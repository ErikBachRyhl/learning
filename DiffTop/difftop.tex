\documentclass[11pt]{article}
\input{../preamble.tex}   % path is relative to the topic folder

\title{Math 214 - Differential Topology}
\author{Erik Bach Ryhl}
\date{\today}

\graphicspath{{./figures}}

\begin{document}
\maketitle
\tableofcontents
\newpage

\section{Tangent Vectors and Differentials}
\subsection{Overview}
\begin{itemize}
    \item \textgreen{Tangent vectors}
    \item \textgreen{Tangent space}
    \item \textgreen{Smooth maps between manifolds induce maps between tangent spaces: the differential} 
    \item \textgreen{Tangent vectors in local coordinates} 
    \item \textgreen{Tangent space basis: All tangent vectors at \(p\) can be written as a linear combination of these. } 
    \item \textgreen{The coordinates of a tangent vector depends on all the coordinate maps chosen. Example with the change of coordinates rule} 
    \item \textgreen{Review of differentiability in Euclidean space} 
    \item \textgreen{Review of chain rule in Euclidean space} 
\end{itemize}

\subsection{Problems}
\textbf{From HW} 
\begin{itemize}
    \item
\end{itemize}

\textbf{Extra} 
\begin{itemize}
    \item Lee Problem 3.2
\end{itemize}

\subsection{Tangent Vectors as Derivations}
Defined as \textbf{derivations at a point \(p \in M\)}, i.e. \(\mathbb{R}\)-linear maps satisfying the Leibniz Rule. Equipped with a natural vector space structure, we get the vector space of all derivations at \(p\) - this is the \textbf{tangent space \(T_p M\)}. 

Just like a derivative, tangent vectors send constant functions to zero. Also, if two functions \(f, g \in C^\infty(M)\) vanish at the same point \(p \in M\), then \(v_p(fg) = 0\) by the Leibniz rule. This actually recovers an important property of derivatives (which we are trying to generalize). For if we take any function \(C ^\infty(M)\) and put local coordinates \(\varphi = (x^1, \dots , x^n)\) around \(p \in M\), then we can Taylor-expand the coordinate representation of \(f\) around the coordinate representation of \(p\): 

Let \(\hat{f} \coloneqq f \circ \varphi ^{-1}  : \hat{U} \subseteq \mathbb{R} ^n \to \mathbb{R}\), let \(\hat{p} = \varphi (p) = (x^1(p), \dots , x^n(p))\) and let \(y \in \hat{U}\). Then \begin{align*}
    \hat{f}(y) = \hat{f}(\hat{p}) + \frac{\partial \hat{f}}{\partial x^i}(\hat{p})(y^i - \hat{p}^i) + (y^i - \hat{p}^i)(y^j - \hat{p}^j) \int _0 ^1 (1 - t) \frac{\partial ^{2} \hat{f}}{\partial x^i \partial x^j} (\hat{p} + t(y - \hat{p})) dt
\end{align*}
Since \(y^i - \hat{p}^i : \mathbb{R} ^n \to \mathbb{R}\), are a smooth maps between manifolds vanishing at the point \(\hat{p}\), any tangent vector \(v \in T_{\hat{p}} \mathbb{R} ^n\) will annihilate their product due to the Leibniz rule. Similarly, \(\hat{f}(\hat{p})\) is a constant. So the only term that remains is \begin{align}\label{eq:tangent_vector_coordinate_rep_action}
    v(\hat{f}(\hat{p})) = \frac{\partial \hat{f}}{\partial x^i}(\hat{p})\left( v(y^i) - v(\hat{p}^i) \right)  = \frac{\partial \hat{f}}{\partial x^i}(\hat{p})v(y^i) 
\end{align} 
So, the important property of derivatives we recover is that \textbf{the output of acting with a tangent vector on a smooth function will only depend on the functions first order change}. In other words, tangent vectors on manifolds are used for linearly approximating the first order change of smooth functions on manifolds. 

Notice that we could act with a tangent vector \(v \in T_{\hat{p}} \mathbb{R} ^n\) exactly because tangent vectors act \textbf{locally} - they only care about the behavior of our functions arbitrarily close to the specific point we are at on the manifold. Hence if two smooth functions \(f, g \in C^\infty(M)\) agree on some small neighborhood around \(p\), then \(v_p f = v_p g\). In general, for any open subset \(U\) of a manifold (called an \textbf{open submanifold} with subset topology and the obvious atlas constructed from restricting the charts on \(M\)), the differential of the inclusion \(d\iota_p : T_p U \to T_p M\) is an isomorphism between \(T_p U \cong T_p M\). 

\subsection{Differentials}
\textbf{Differentials} are \textbf{linear maps} between tangent spaces of manifolds. Any smooth function \(F: \mathcal{M}\to N\) between two manifolds induces a map between respective tangent spaces through the differential. Given \(p \in M\), \(v \in T_p M\) and \(g \in C^\infty(N)\), we define \(dF_p : T_p \mathcal{M}\to T_{F(p)}N\) as follows: \begin{align*}
    (dF_p v) (g) = v_p (g \circ F)
\end{align*}

\textbf{Properties of differentials:}\begin{itemize}
    \item Differentials are linear maps. Think \((Av)(f) = w(f)\) basically.
    \item Chain rule from calculus abstractly becomes a composition of linear maps: If \(G : N \to P\) is another smooth map, \(d(G \circ F)_p = dG_{F(p)} \circ dF_p : T_p \mathcal{M}\to T_{G(F(p))}N\)
    \item \(d(\operatorname{Id}_\mathcal{M}) = \operatorname{Id}_{T_p M}\)
    \item \textbf{A diffeomorphism \(F : \mathcal{M}\to N\) induces an isomorphism between tangent spaces with \(\left( dF_p \right)^{-1}  = d(F^{-1} )_{F(p)}\)}
\end{itemize} 

We see that the action of an (abstract) tangent vector \(v \in T_p M\) acting on \(f \in C^\infty(M)\) can be "pushed forward" in local coordinates by a chart \(\varphi : U \to  \hat{U} \subseteq \mathbb{R} ^n\): 
\begin{align} \label{eq:tangent_vector_action}
    v_p(f) = v_p(f \circ \varphi ^{-1} \circ \varphi ) = v_p(\hat{f} \circ \varphi ) = (d \varphi _p v_p) (\hat{f}) \textred{\  = v^i \frac{\partial }{\partial x^i} \bigg|_{p} f = v^{i} \frac{\partial \hat{f}}{\partial x^i}  (\hat{p}) } 
\end{align}
The red text is to indicate that we are about to introduce the necessary machinery. But it is already put there to parallel eq. \ref{eq:tangent_vector_coordinate_rep_action} - if \(v^i = v(y^i)\), then they are the same! And this is what we'll see.

\subsubsection{Tangent space of a vector space}
Given a vector space, a vector \(a \in V\) (thought of as a point) and a vector \(v \in V\) (thought of as a direction) gives for every \(f \in C^\infty(V)\) a derivation: 
\begin{align*}
D_v \big|_{a}f = \frac{d}{dt} \bigg|_{t = 0} f(a + tv)     
\end{align*}
The map \(v \mapsto D_v \big|_{a}\) is in fact a canonical isomorphism between \(V\) and \(T_a V\) - hence the tangent space of a vector space can be identified with the vector space itself. And if one has a linear map \(L : V \to W\) between vector spaces, the differential \(dL_a : T_a V \to T_{L(a)}W\) gives a commutative diagram through \begin{align*}
    d L_a (D_v \big|_{a} )(f) = D_{Lv} \big|_{La} f 
\end{align*}   

\begin{example}
    Since the vector space \(GL(n, \mathbb{R})\) is an open submanifold of the vector space \(M(n, \mathbb{R})\), we can use both the identification \(T_p GL(n, \mathbb{R} ) \cong T_p M(n, \mathbb{R})\) and the fact that \(M(n, \mathbb{R})\) is a vector space such that \(T_p M(n, \mathbb{R} ) \cong M(n, \mathbb{R})\) to see that \(T_p GL(n, \mathbb{R} ) \cong M(n, \mathbb{R})\). 

    Recall that \(GL(n, \mathbb{R})\) is in fact a Lie group, and as such \(T_e GL(n, \mathbb{R} ) = \mathfrak{g} \cong M(n, \mathbb{R})\). In other words, this canonical construction proves why the Lie algebra of \(GL(n, \mathbb{R})\) is the set of \textit{all} \(n \times n\) matrices over \(\mathbb{R} \).    
\end{example}
\textred{Check up on this after reviewing Lie algebras!}

\subsection{Tangent Vectors in Local Coordinates}
For any \(p \in M\), pick a chart \((U, \varphi) = (U, (x^1, \dots , x^n))\) that contains \(p\). Since \(\varphi : U \to \hat{U} \subseteq \mathbb{R} ^n\) is a diffeomorphism between smooth manifolds (\(U\) is an open submanifold of \(M\) and \(\hat{U}\) is an open submanifold of \(\mathbb{R} ^n\)), its differential is an isomorphism between tangent spaces: \begin{align*}
    d \varphi _p : T_p U \to T_{\varphi (p)} \hat{U}.
\end{align*} 

As mentioned, we can always canonically identify the tangent space of an open submanifold with the tangent space of the ambient manifold. Doing this on both sides, we get that \begin{align*}
    d \varphi _p : T_p \mathcal{M}\to T_{\varphi (p)} \mathbb{R} ^n
\end{align*}
is a canonical isomorphism. Since we already have a basis for \(T_{\varphi (p)} \mathbb{R} ^n\) given by \begin{align*}
    \frac{\partial }{\partial x^1} \bigg|_{\varphi (p)}, \dots ,  \frac{\partial }{\partial x^n} \bigg|_{\varphi (p)},
\end{align*} 
where these are \underline{Euclidean partial derivatives}, we can just "lift these up" to the manifold through the isomorphism \(d \varphi _p\) to obtain a basis for \(T_p M\)! We define them with the notations: \begin{align*}
    \frac{\partial }{\partial x^i} \bigg|_{p} = (d \varphi _p)^{-1} \left( \frac{\partial }{\partial x^i} \bigg|_{\varphi (p)} \right) = d\left(\varphi ^{-1}  _{\varphi (p)}\right)\left( \frac{\partial }{\partial x^i} \bigg|_{\varphi (p)} \right)
\end{align*}
and since it is a basis, \textbf{any (abstract) tangent vector \(T_p M\) can be written as} \begin{align*}
    v_p = v^i \frac{\partial }{\partial x^i} \bigg|_{p}.
\end{align*}
The action of such a tangent vector on a map \(f \in C^\infty(M)\) can then finally be computed explicitly: \begin{align*}
    \frac{\partial}{\partial x^i} \bigg|_{p} f = d\left(\varphi ^{-1}  _{\varphi (p)}\right)\left( \frac{\partial }{\partial x^i} \bigg|_{\varphi (p)} \right) (f) = \frac{\partial }{\partial x^i} \bigg|_{\varphi (p)} \left( f \circ \varphi ^{-1} \right) = \frac{\partial \left( f \circ \varphi ^{-1}  \right) }{\partial x^i} (\varphi (p)) = \frac{\partial \hat{f}}{\partial x^i}(\hat{p})
\end{align*} 
where it should always be noted that "pulling the function up on the fraction" means that we are thinking about Euclidean derivatives. This is just the abstraction we wanted: \textbf{the (abstract) tangent basis vector for the \(i\)'th coordinate function for \(T_p M\) acts in local coordinates by taking the \(i\)'th partial derivative of the coordinate representation of \(f\) at the coordinate representation of the point \(p\)}. A good rule of thumb then, is that one can turn the abstract action of a tangent vector into a Euclidean partial derivative by putting hats on everything and taking the Euclidean partial derivative. 

It is even easy to find the coordinates for a tangent vector \(v_p \in T_p M\), since \textbf{they are just \(v_p\) applied to the coordinate functions}: \begin{align*}
    v_p (x^i) = \left( v^j \frac{\partial }{\partial x^j}\bigg|_{p} \right)  (x^i) &= d \left( \varphi ^{-1} _{\varphi (p)} \right) \left( v^j \frac{\partial }{\partial x^j}\bigg|_{\varphi (p)} \right) (x^i) = v^j\frac{\partial }{\partial x^j}\bigg|_{\varphi (p)} \left( x^i \circ \varphi ^{-1}  \right)\\
    &= v^j \frac{\partial \left( x^i \circ \varphi ^{-1}  \right) }{\partial x^j} (\varphi (p)) = v^j \frac{\partial \left( \pi ^i \circ \varphi \circ \varphi ^{-1}  \right) }{\partial x^j} (\varphi (p)) \\
    &= v^j \frac{\partial \left( \pi ^i \right) }{\partial x^j} (\varphi (p))\\
    &= v^j \delta ^i _j \\
    &= v^i,
\end{align*}
where it was used that by definition, \(x^i = \pi ^i \circ \varphi \) with \(\pi ^i : \mathbb{R} ^n \to \mathbb{R}\) the projection map in Euclidean space. We have now justified \ref{eq:tangent_vector_action}. We can use the same "lift up by the charts" idea to get an expression for the differential in coordinates. 

\subsection{Differentials in Local Coordinates}
Recall the total differential \(DF(a)\), which is defined as the linear map between the vector spaces that \(F: V \to W\) maps between such that \begin{align*}
    \lim_{v \to 0} \frac{|F(a + v) - F(a) - DF(a) v|}{|v|} = 0 
\end{align*}
i.e. it is a linear map which approximates the change of the map \(F\) at \(a \in V\).  

One can prove the (now familiar) chain rule for composition of differentiable maps \begin{align*}
    D(G \circ F)(a) = DG(F(a)) \circ DF(a).
\end{align*}

Introducing the language of partial derivatives, we then find that the matrix representation of the total differential is the Jacobian, i.e. that \begin{align*}
    \left( DF(a) \right) ^i _j = \frac{\partial F^i }{\partial x^j}(a), 
\end{align*}
such that the chain rule for partial derivatives is just matrix multiplication: \begin{align*}
    \left( D(G \circ F)(a) \right) ^i _j = \left( DG(F(a)) \circ DF(a) \right) ^i _j = \left( DG(F(a)) \right)^i _k \left( DF(a) \right) ^k _j = \frac{\partial G^i}{\partial y^k}(F(a)) \frac{\partial F^k}{\partial x^j} (a)  
\end{align*}

These are exactly the things we are trying to generalize to our manifolds. 

\paragraph{Euclidean Version:}
First, let us look at a Euclidean map \(F: U \subseteq \mathbb{R} ^n \to V \subseteq \mathbb{R} ^m\), but thinking of Euclidean space as a manifold now. Let \(p \in U\) with local coordinates \((x^1, \dots , x^n)\) and let \((y^1, \dots , y^m)\) be local coordinates for \(V\). Let us take some tangent vector in \(T_{p} U \cong T_{p}\mathbb{R} ^n\). Then we can push it forward with the differential
\begin{align*}
    d F_{p} \left( \frac{\partial }{\partial x^i} \bigg|_{p}  \right) f = \frac{\partial }{\partial x^i}\bigg|_{p} \left( f \circ F \right) = \frac{\partial f}{\partial y^j}(F(p)) \frac{\partial F^j}{\partial x^i}(p) = \left( \frac{\partial F^j}{\partial x^i}(p) \frac{\partial }{\partial y^j} \bigg|_{F(p)}   \right) f
\end{align*}  
such that \begin{align*}
    dF_p \left( \frac{\partial }{\partial x^i} \bigg|_{p}  \right) =\frac{\partial F^j}{\partial x^i}(p) \frac{\partial }{\partial y^j} \bigg|_{F(p)}.
\end{align*}
Note that this is all Euclidean and is exactly what we would expect. Parallel this with conventions for representing linear maps in linear algebra: Given a linear map \(L: V \to W\) between spaces with bases \(\left\{ e_i \right\}_{i = 1}^n \) and \(\left\{ f_j \right\}_{j = 1}^m \) respectively, we by convention write \begin{align*}
    Le_i = A^j_i f_j.
\end{align*}
Now, given any vector \(v \in V\) represented by \begin{align*}
    v = v^i e_i
\end{align*} 
we would find that \begin{align*}
    Lv = L(v ^i e_i) = v^i Le_i = v^i A^j_i f_j = (A ^j _i v^i )f_j = (Av)^j f_j.
\end{align*}
So the coordinate vector of \(v\) is sent to the coordinate vector \(Av\). In other words, the representation of the linear map acts with matrix multiplication on the coordinate representation of the vector. This directly lets us see that the \(i\)'th column of \(A\) is just the coordinate vector of \(L(e_i)\). So remember that \textbf{the \(i\)'th column of \(A\) is the image of the \(i\)'th basis vector of the domain of the map that \(A\) represents.}

Replacing \(L \leftrightarrow dF_p\) and \(e_i \leftrightarrow \frac{\partial }{\partial x^i} \big|_p\) and \(f_j \leftrightarrow \frac{\partial }{\partial y^j} \big|_{F(p)}\), we can directly interpret \begin{align*}
    \frac{\partial F^j}{\partial x^i} (p)
\end{align*}  
as the \(j\)'th row and \(i\)'th column of the Jacobian of \(DF(p)\) and hence that column \(j\) in the Jacobian matrix is the coordinate vector of the basis vector \(\frac{\partial }{\partial x^i} \big|_p \in T_p \mathbb{R} ^n\) expressed in the basis \(\frac{\partial }{\partial y^j}\big|_{F(p)} \in T_{F(p)} \mathbb{R} ^m\). 

Let us generalize to manifolds. Given a smooth map \(F: \mathcal{M}\to N\), choose smooth coordinate charts \((U, \varphi ) = (U, x^1, \dots , x^m)\) for \(M\) containing \(p\) and \((V, \psi) = (V, y^1, \dots , y^n)\) for \(N\) containing \(F(p)\). We can go through the same steps above but just with the coordinate representation \(\hat{F} = \psi \circ F \circ \varphi ^{-1} : \varphi (U \cap F ^{-1} (V)) \to \psi (V)\) and we would get that \(d \hat{F}_{\hat{p}} \) is represented by the Jacobian matrix of the coordinate reprensetative for \(F\) at the coordinate representative for \(p\). But we want to figure out what it is directly for \(dF_p\): \begin{align*}
    dF_p \left( \frac{\partial}{\partial x^i}\bigg|_{p} \right) &= dF_p \left( d(\varphi ^{-1} )_{\hat{p}} \left( \frac{\partial}{\partial x^i}\bigg|_{\hat{p}}\right)\right) = d(\psi ^{-1} )_{\psi(F(\varphi ^{-1} (x)))} d \hat{F}_{\hat{p}} \left( \frac{\partial}{\partial x^i}\bigg|_{\hat{p}}  \right) \\
    &= d(\psi ^{-1} )_{\hat{F}(\hat{p})} \left( \frac{\partial \hat{F}^j}{\partial x^i}(\hat{p}) \frac{\partial }{\partial y^j} \bigg|_{\hat{F}(\hat{p})}\right) \\
    &= \frac{\partial \hat{F}^j}{\partial x^i}(\hat{p}) \left[  d(\psi ^{-1} )_{\hat{F}(\hat{p})} \left( \frac{\partial}{\partial y^j}\bigg|_{\hat{F}(\hat{p})}\right)  \right] \\
    &= \frac{\partial \hat{F}^j}{\partial x^i}(\hat{p}) \frac{\partial }{\partial y^j}\bigg|_{F(p)}
\end{align*}  
\begin{align*}
    \implies \boxed{dF_p \left( \frac{\partial}{\partial x^i}\bigg|_{p}  \right) = \frac{\partial \hat{F}^j}{\partial x^i}(\hat{p}) \frac{\partial }{\partial y^j}\bigg|_{F(p)}}
\end{align*}
Hence \(dF_p\) is represented in a coordinate basis by the Jacobian matrix of the coordinate representation of \(F\). This was the ultimate goal of our abstraction of derivatives: to have a way to talk about derivatives between manifolds, such that it reproduces the Euclidean version once we are in local coordinates, but which is defined purely in terms of abstract actions on maps on between manifolds.

\subsection{Change of coordinates}

Let \((U, \varphi = (x^1, \dots , x^n))\) and \((V, \psi = (\tilde{x}^1, \dots , \tilde{x}^n))\) be charts for \(M\) and \(p \in U \cap V\). If \(x \in \hat{U}\subseteq \mathbb{R} ^n\), one can think of the representation of the transition map as \begin{align*}
    \psi \circ \varphi ^{-1} (x) = (\tilde{x}^1(x), \dots, \tilde{x}^n(x)),
\end{align*}
i.e. that \textbf{the new first coordinate is a smooth function of \textit{all} the other old coordinates} etc. Note the emphasis on "all" here. This is of course a slight abuse of notation since we can't directly apply the coordinate function \(\tilde{x}^i : \mathcal{M}\to \hat{V}\subseteq \mathbb{R} ^n\) to a point in \(\mathbb{R} ^n\), but as long as we remember that the transition maps "factors through" the manifold, it is a good way to think about it.

Just like chart maps are diffeomorphisms, so are their compositions. In other words, transition maps are diffeomorphisms, and hence their differentials are isomorphisms. With the general formula for the coordinate representation of the differential action, we find that \begin{align*}
    d(\psi \circ \varphi ^{-1} )_{\varphi (p)} \left( \frac{\partial}{\partial x^i}\bigg|_{\varphi (p)}  \right) = \frac{\partial (\psi \circ \varphi ^{-1} )^j}{\partial x^i} (\varphi (p)) \frac{\partial}{\partial \tilde{x}^j}\bigg|_{\psi (p)} = \frac{\partial \tilde{x}^j}{\partial x^i}(\varphi (p))\frac{\partial}{\partial \tilde{x}^j}\bigg|_{\psi (p)}  ,
\end{align*}

% &= d(\varphi ^{-1} )_{\varphi (p)}\left( \frac{\partial}{\partial x^i}\bigg|_{\varphi (p)}  \right) = d(\psi ^{-1} \circ \psi \circ \varphi ^{-1} )_{\varphi (p)} \left( \frac{\partial}{\partial x^i}\bigg|_{\varphi (p)} \right)  \\
% &= d (\psi ^{-1} )_{\psi (p)} \frac{\partial \tilde{x}^j}{\partial x^i}(\varphi (p))\frac{\partial}{\partial \tilde{x}^j}\bigg|_{\psi (p)}

such that \begin{align*}
    \boxed{\frac{\partial}{\partial x^i}\bigg|_{p} = \frac{\partial \tilde{x}^j}{\partial x^i}(\varphi (p))\frac{\partial}{\partial \tilde{x}^j}\bigg|_{p} = \frac{\partial \tilde{x}^j}{\partial x^i} (x(p)) \frac{\partial}{\partial \tilde{x}^j}\bigg|_{p}}
\end{align*}
where the latter notation used is \(\varphi (p) = (x^1(p), \dots , x^n(p)) \coloneqq x(p)\), which I think makes it a better mnemonic to remember which of the chart representations one is supposed to input.  

Hence for a tangent vector \(v \in T_p M\), which can be written as \(v = v^i \partial / \partial x^i \big|_{p} = \tilde{v}^j \partial / \partial \tilde{x}^j \big|_{p}\) we get \begin{align*}
    \boxed{\tilde{v}^j = \frac{\partial \tilde{x}^j}{\partial x^i}(\varphi (p))  v^i = \frac{\partial \tilde{x}^j}{\partial x^i}(x(p)) v^i }
\end{align*} 

Remember that abstract tangent vectors \(\partial / \partial x^i \big|_{p} \) has the action of taking the \(i\)-th partial derivative of the coordinate representation of a function. Partial derivatives keep all other coordinates constant, so if one changes any coordinate function \(x^j\) of the chart \(\varphi = (x^1, \dots , x^n)\), then "keep all other coordinates constant" means something different. Hence just like in linear algebra, the coordinate representaion depends on the entire basis that one has chosen.    

\begin{example}
    Checking that a map / definition is coordinate independent. See the example that Dr. Freud posted for HW II in the chat.
\end{example}

\subsection{Tangent Vectors as Curves}
Let \(J \subseteq \mathbb{R}\) be some interval. If we want to be very formal, we can denote our smooth chart as \((J, t)\). \(\mathbb{R} \) being one-dimensional gives us a single tangent vector as our basis for any point \(t \in J\), namely \begin{align*}
    \frac{d}{dt}\bigg|_{t_0},
\end{align*} 
where \(t_0 \in J\) is some fixed point we've chosen.

Let us consider \(f \in C^\infty(M)\). Given a smooth curve \(\gamma : J \subseteq \mathbb{R} \to M\), we can use the differential to push our tangent vector forwards to \(M\), since \(d \gamma _{t_0}: \mathbb{R} \to T_{\gamma (t_0)}M\): \begin{align*}
    d \gamma _{t_0}\left( \frac{d}{dt} \bigg|_{t_0} \right)f = \frac{d}{dt} \bigg|_{t_0} (f \circ \gamma) = (f \circ \gamma )^{\prime} (t_0)
\end{align*}
Since the domain of \(d \gamma_{t_0} \) is already Euclidean space, we could use the chain rule without further ado. We define \begin{align*}
    \gamma ^{\prime} (t_0) f \coloneqq d \gamma _{t_0} \left( \frac{d}{dt}\bigg|_{t_0} \right) f = \frac{d}{dt}\bigg|_{t_0} (f \circ \gamma )
\end{align*}

If \((U, \varphi = (x^1, \dots , x^n))\) are charts around \(p = \gamma (t_0)\), we'll write \(\gamma (t) = (x^1(\gamma (t)), \dots , x^n(\gamma (t))) \coloneqq (\gamma ^1(t), \dots , \gamma ^n (t))\). Then using our coordinate representation formula for \(dF_p (v)\) we find that \begin{align*}
    \boxed{\gamma ^{\prime} (t_0) = \frac{d \gamma ^i}{d t} (t_0) \frac{\partial }{\partial x^i} \bigg|_{\gamma (t_0)}}
\end{align*}
Every tangent vector \(v \in T_p M\) is the velocity vector of some curve. By picking the curve \(\gamma (t) = \varphi ^{-1} (t v^1, \dots, t v^n) \coloneqq (t v^1, \dots , tv^{n} )\) and a chart on \(M\) centered at \(p \in M\), we see that \begin{align*}
    \gamma ^{\prime} (0) = \frac{d \hat{\gamma}^i}{dt} (0) \frac{\partial }{\partial x^i}\bigg|_{\gamma (0)} = v^i \frac{\partial }{\partial x^i} \bigg|_{p} = v  
\end{align*} 

In fact, for any composite maps between curves and manifold maps we define with the prime notation as follows. Take \(F : \mathcal{M}\to N\) and \(\gamma (t)\) as before. Then \begin{align*}
    (F \circ \gamma )^{\prime} (t_0) \coloneqq d(F \circ \gamma )_{t_0} \left( \frac{d}{dt}\bigg|_{t_0} \right) = dF_{\gamma (t_0)} \circ d \gamma _{t_0} \left( \frac{d}{dt}\bigg|_{t_0} \right) = dF _{\gamma (t_0)} (\gamma ^{\prime} (t_0)).
\end{align*} 
This also makes it clear that if we take a curve \(\gamma : J \to M\) with \(\gamma (t_0) = p\) and \(\gamma ^{\prime} (t_0) = v\), then \begin{align*}
    dF_p (v) = dF_{\gamma (t_0)} (\gamma ^{\prime} (t_0)) \coloneqq (F \circ \gamma )^{\prime} (t_0)
\end{align*}
Often we choose a chart centered at \(p\) and choose \(t_0 = 0\). 

\subsection{The Tangent Bundle}

The tangent bundle is defined as the disjoint union of all the tangent spaces of \(M\): \begin{align*}
    T\mathcal{M}= \coprod _{p \in M} T_p \mathcal{M}
\end{align*}

Every element is written as \((p, v) \in TM\) and we have the natural projection map \(\pi : T\mathcal{M}\to M\) sending \((p, v) \mapsto p\). There is no canonical way to project onto the second factor, since each tangent space is formally disjoint to all other tangent spaces. In other words, there is no canonical way to determine which vector one should transition to when transitioning between tangent spaces. The only canonical vector in any vector space is the zero vector, so when the zero vector is involved one can sometimes make canonical identifications. Just like with the zero section \(Z\) for example.

For any \(v \in T_p M\), we can identify it with \((p, v) \in TM\) canonically, since the injection of \(p\) is canonical.  

\subsection{The manifold structure of \(TM\)}
One can think of \(TM\) as locally attaching to each point of \(p \in M\) the entire tangent space \(T_p M\). The word "locally" is very important here, since one cannot always globally write the tangent bundle as a cartesian product. But locally, that intuition is good.

The open chart domains on \(TM\) will be made from open chat domains \(U \subseteq M\) through the preimage of the projection map. First of all, note that for any \(p \in M\), \begin{align*}
    \pi ^{-1} (p) = T_p M,
\end{align*} 
where \(\pi ^{-1} (p)\) is called \textbf{the fiber over \(p\)}. Then \begin{align*}
    \pi ^{-1} (U) = \pi ^{-1} \left( \bigcup_{p \in U} p \right) = \bigcup_{p \in U} \pi ^{-1} (p) = \bigcup_{p \in U} T_p M,
\end{align*} 
which means that \(\pi ^{-1} (U)\) is the union of all the tangent vectors to all points in \(U\), or equivalently, the union of all the fibers under \(\pi\) over points in \(U\). The charts are defined as pairs \((\pi ^{-1} (U), \tilde{\varphi })\), with \(\tilde{\varphi }: TM \to \varphi (U) \times \mathbb{R} ^n \subseteq \mathbb{R} ^{2n}\) as \begin{align*}
    \tilde{\varphi } \left( v^i \frac{\partial}{\partial x^i}\bigg|_{p}  \right) = (\varphi (p), v_p) = (x^1 (p), \dots , x^n(p), v^1, \dots , v^n).
\end{align*} 
It is a bijection, since \begin{align*}
    \tilde{\varphi}^{-1} (x^1(p), \dots , x^n(p), v^1, \dots , v^n) \coloneqq v^i \frac{\partial}{\partial x^i}\bigg|_{\varphi ^{-1} (x)} 
\end{align*}
is an explicit inverse. 

Note that to use \(\tilde{\varphi}\), where one "strips" the coordinates of tangent vector from the basis vectors, the tangent vector needs to be written in the basis related to the charts specified by \(\varphi (p)\). To illustrate what I mean, consider \((\pi ^{-1} (U), \tilde{\varphi})\) and \((\pi ^{-1} (V), \tilde{\psi })\) with \((p, v) \in \pi ^{-1} (U) \cap \pi ^{-1} (V) = \pi ^{-1} (U \cap V)\). Then the transition map \(\tilde{\psi } \circ \tilde{\varphi}^{-1} \) takes a little bit of computation. Let \((x^1, \dots , x^n, v^1, \dots , v^n) \in \mathbb{R} ^{2n}\): \begin{align*}
    \tilde{\psi }\circ \tilde{\varphi }^{-1} (x^1, \dots , x^n, v^1, \dots , v^n) &= \tilde{\psi } \left( v^i \frac{\partial}{\partial x^i}\bigg|_{\varphi ^{-1} (x)}  \right) \\
    &= \tilde{\psi} \left( v^i\frac{\partial (\psi \circ \varphi ^{-1} )^j}{\partial x^i} (x) \frac{\partial}{\partial \tilde{x}^j}\bigg|_{\varphi ^{-1} (x)}  \right) \\
    &= \tilde{\psi} \left( v^i\frac{\partial \tilde{x}^j}{\partial x^i} (x) \frac{\partial}{\partial \tilde{x}^j}\bigg|_{\psi ^{-1} (\tilde{x})}  \right) \\
    &= \left( \tilde{x}^1(x), \dots , \tilde{x}^n(x), \frac{\partial \tilde{x}^1}{\partial x^i} (x) v^i, \dots , \frac{\partial \tilde{x}^n}{\partial x^i} (x)  v^i \right) 
\end{align*}

Note that since \(\varphi^{-1} (x) \in U \cap V\), we can write it as either \(\psi ^{-1} (x)\) or \(\varphi ^{-1} (\tilde{x})\). To remember the above a bit more easily, just note the linear algebra analogue: \begin{align*}
    \tilde{\psi } \circ \tilde{\varphi }^{-1} (x, v) = (\tilde{x}(x), J(x) v),
\end{align*}  
where \begin{align*}
    J(x) = \frac{\partial \tilde{x}^j}{\partial x^i}(x) 
\end{align*}
is just the Jacobian of the transition map. The reason we need all the transition map differentiation is because it would have been completely wrong to write \begin{align*}
    \tilde{\psi } \left( v^i \frac{\partial}{\partial x^i}\bigg|_{\psi ^{-1} (x)}  \right)  = \left( \tilde{x}^1 (x), \tilde{x}^n(x), v^1, \dots , v^n \right),
\end{align*}
since if we would then be implictly equating \begin{align*}
    \textred{v = v^i \frac{\partial}{\partial \tilde{x}^i}\bigg|_{\psi ^{-1} (x)}} 
\end{align*}
i.e. combining coordinates in one bases with basis vectors in another. The transition map above is smooth and with a few more arguments we see that the construction gives a smooth structure for \(TM\). This immediately implies that \(\tilde{\varphi} : \pi ^{-1} (U) \to \varphi (U) \times \mathbb{R} ^n\) is a diffeomorphism. 

Hence if a manifold \(M\) can be covered by a single chart, then \(\varphi (M) = \hat{U}\subseteq \mathbb{R} ^n\) is a diffeomorphism, and thus \(T\mathcal{M}\cong \mathcal{M}\mathbb{R} ^n\) are diffeomorphic. So in cases like this, the tangent bundle \textit{can} be considered as a cartesian product \textit{globally}.

\textred{Manifold chart lemma is used to finish the proof that \(TM\) is a \(2n\) dimensional smooth manifold}

\begin{example}
    \(TS^1 \cong S^1 \times R\).   
\end{example}

\subsection{The Global Differential} 
Every smooth map \(F : \mathcal{M}\to N\) induces a smooth map \(dF : T\mathcal{M}\to TN\) called the global differential. It is the map whose restriction to each tangent space \(T_p \mathcal{M}\subseteq TM\) is \(dF_p\). Hence it's action on \(v \in TM\) is \begin{align*}
    dF (v) = dF_p (v)
\end{align*}

Writing the map in local coordinates we see that it is smooth, since
\begin{align*}
    \tilde{dF} (x^1, \dots , x^n, v^1, \dots , v^n) &= \tilde{\psi } \circ dF \circ \tilde{\varphi}^{-1} (x^1, \dots , x^n, v^1, \dots , v^n) \\
    &= \tilde{\psi } \circ dF \left( v^i \frac{\partial}{\partial x^i}\bigg|_{\varphi ^{-1} (x)}  \right) \\
    &= \tilde{\psi } \left( dF_{\varphi ^{-1} (x)} \left( v^i \frac{\partial}{\partial x^i}\bigg|_{\varphi ^{-1} (x)}  \right) \right)  \\
    &= \tilde{\psi } \left( v^i \frac{\partial \hat{F}^j}{\partial x^i} (\varphi (\varphi ^{-1} (x)) ) \frac{\partial}{\partial \tilde{x}^j}\bigg|_{\varphi ^{-1} (x)}  \right) \\
    &= \left( \psi^1(F(\varphi ^{-1} (x))), \dots , \psi ^n (F(\varphi ^{-1} (x))),\frac{\partial \hat{F}^1}{\partial x^i} (x) v^i, \dots , \frac{\partial \hat{F}^n}{\partial x^i} (x) v^i \right) \\
    &= \left( \hat{F}^1(x), \dots , \hat{F}^n(x), \frac{\partial \hat{F}^1}{\partial x^i} (x) v^i, \dots , \frac{\partial \hat{F}^n}{\partial x^i} (x) v^i  \right), 
\end{align*}
which is smooth because \(F\) is. Of course global differentials has exactly the same nice properties that local ones have. Note also that differentials "respect" base-points: \(\pi (dF(v_p)) = F(p)\), since \(dF(v_p) = dF_p(v_p) \in T_{F(p)}N\).   


\subsection{The cotangent space}

\subsection{Differentials of \(C^\infty(M)\) maps as covectors and a covector basis}


\section{Lie Groups}

\section{Vector Bundles and Differential Forms}
\paragraph{Abstract}
\newpage\lecture{17}{Thu 23 Oct}{Introduction to Vector Bundles}
\begin{definition}[Vector Bundle]
    A (rank \(k\), real, smooth) \textbf{vector bundle} over \(M\) is a smooth manifold \(E\) of dimension \(n + k\), and a smooth map \(\pi : E \to M\) such that \begin{itemize}
        \item For each \(p \in M\), the \textbf{fiber} \(\pi ^{-1} (p)\) has the structure of a (real \(k\)-dimensional) vector space, and
        \item (\textbf{Local Triviality}) For each \(p \in M\), there is a nbhd \(U\) of \(p\) and a diffeomorphism \(\phi : \pi ^{-1} (U) \to U \times \mathbb{R} ^k\) such that for each \(p \in U\), the restriction \begin{align*}
            \phi \big|_{\pi ^{-1} (p)}: \pi ^{-1} (p) \to  \left\{ p \right\} \times \mathbb{R} ^k 
        \end{align*} is an isomorphism of vector spaces. 
    \end{itemize}  
    \[
    \begin{tikzcd}
    \pi ^{-1} (U) \arrow[r, "\phi", "\sim"'] \arrow[d, "\pi"'] & U \times \mathbb{R} ^k \arrow[d, "\pi _1"] \\
    U \arrow[r, "\operatorname{id} "']                & U
    \end{tikzcd}
    \]

    A vector bundle is thus a triplet, often just written as \begin{align*}
        E \overset{\pi }{\longrightarrow} M
    \end{align*}
    In the context of a vector bundle, \(E\) is called the \textbf{total space}, \(M\) is called the \textbf{base space} and \(\pi\) is called the \textbf{projection}.    
\end{definition}

So just like the tangent bundle, we think of attaching a vector space to each point of \(M\) like a piece of string (a fiber is vizualised this way, hence the name). But vector bundles are more general than the tangent bundle construction. I think that they were inspired by the tangent bundle perhaps. 

\begin{note}
    Write some more intuition for it here
\end{note} 

\begin{example}[Trivial Vector Bundle]
    The trivial vector bundle has \(E = \mathcal{M}\times \mathbb{R} ^k\), \(\pi = \pi _1 : \mathcal{M}\times \mathbb{R} ^k \to M\). 
\end{example}

\begin{remark}
    It follows from the definition that \(\pi\) is a submersion and that the vector space operations on the fibers \(\pi ^{-1} (p)\) "depend smoothly on \(p\)."  
\end{remark}

\begin{remark}
    Note something very important: By the local trivialization condition, each vector space at each point isn't totally unrelated anymore (like we had with the tangent bundle); they are "bundled together" to locally look like the trivial bundle. So the requirement of the existence of the diffeomorphism \(\phi \) introduces will make it possible to relate vectors between different fibers locally, I think. 
\end{remark}

\begin{example}[Tangent Bundle]
    
\end{example}

\begin{definition}[Vector Bundle Isomorphism]
    Let \(E_1 \overset{\pi_1 }{\longrightarrow} M\) and \(E_2 \overset{\pi_2 }{\longrightarrow} M\) be vector bundles. An \textbf{isomorphism} is a diffeomorphism \(\phi : E_1 \to E_2\) such that for each \(p \in M\), \begin{align*}
        \phi \big|_{\pi ^{-1} (p)} : \pi _1 ^{-1} (p) \to \pi _2 ^{-1} (p)
    \end{align*} 
    is a vector space isomorphism.
    \[
    \begin{tikzcd}
    E_1 \arrow[dr, "\pi _1"'] \arrow[rr, "\phi", "\sim"'] & & E_2 \arrow[dl, "\pi _2"] \\
    & \mathcal{M}&
    \end{tikzcd}
    \]
\end{definition}

\begin{note}
    Contrast this to the local trivialization condition.
\end{note}

\begin{definition}{Trivial Bundle}
    A vector bundle \(E \overset{\pi }{\longrightarrow} \mathcal{M} \) is \textbf{trivial} if there is a vector bundle isomorphism \(E \cong \mathcal{M}\times \mathbb{R} ^k\). 
    
    In other words, a vector bundle is trivial if is is vector bundle isomorphic to the trivial bundle.
\end{definition}

\textbf{Motivating question:} When is a vector bundle trivial?

\begin{note}
   Fill out the rest of your lecture 23/10 here!
\end{note}


\newpage\lecture{18}{Tue 28 Oct}{1-forms, Integration and Exactness}
\paragraph{Abstract} The main purpose of the lecture was to study 1-forms on smooth manifolds and their relation to integration. We first defined 1-forms and what it means for them to be integrated along a path \(\gamma : [a, b] \to M\). We showed reparameterization invariance of this definition. Then we defined what it means for a 1-form to be \textbf{exact} and showed an important consequence of exactness: integration along curves only depends on endpoints.

However, if we want to check for exactness, and we can't infer a function \(f : \mathcal{M}\to \mathbb{R} \) such that \(\alpha  = df\), then it isn't feasible to integrate along all curves in \(M\) to check if the answer only depends on the endpoints. 

It turns out that in \(\mathbb{R} ^n\), one can show that exactness is equivalent to the statement that \begin{align*}
    \frac{\partial \alpha _i}{\partial x^j} = \frac{\partial \alpha _j}{\partial x^i}  
\end{align*} 
for all \(i, j = 1, \dots , n\). We ended with an example of how this can fail when we aren't in \(\mathbb{R} ^n\) by explicit construction of a 1-form that gives back \(2 \pi \) times the winding number of a loop, which is always an integer. This is not trivial to show and will come back when we get to De Rham cohomology. 

\newpage\begin{definition}[1-form]
    Let \(M\) be a smooth manifold. A \textbf{1-form} \(\alpha\) on \(M\) is a smooth section of \(T^{\ast} M\). So for each \(p \in M\), \begin{align*}
        \alpha (p) : T_p \mathcal{M}\to \mathbb{R} 
    \end{align*}  
    is a linear map depending smoothly on \(p\). That is, in local coordinates \(x^1, \dots , x^n\) we can write \begin{align*}
        \alpha = \alpha _i dx^i, \qquad dx^i \left( \frac{\partial}{\partial x^j}  \right) = \delta ^i _j
    \end{align*}
    with \(\alpha _i (x^1, \dots , x^n) \in \mathbb{R} \) a smooth function of \(x^1, \dots , x^n\). \textred{When picking out coordinates with the differentials of the coordinate bases, should we evaluate at a point, or how does one formalize this with global differential. Is it just notation for that?} 
\end{definition}

Once we have 1-forms, we can define what it means to integrate them 
\begin{definition}[Integral of a 1-form]
    Let \(\gamma : [a, b] \to M\) be a smooth curve. The we define \begin{align*}
        \int _\gamma  \alpha = \int _a ^b \alpha (\gamma ^{\prime} (t))dt.
    \end{align*} 

    \textred{Input sketch here!}
\end{definition}

The definition above seems a bit circular: isn't \(dt\) a differential too, or what is going on here? For now we will accept Riemann/Lebesgue integration as being an operator giving us back the number we are used to when integrating in \(\mathbb{R} ^n\). We will come back to this.

\begin{proposition}[Reparameterization Invariance]
     \begin{align*}
        \int _\gamma \alpha 
     \end{align*}
     is independent of the (oriented) parameterisation of \(\gamma \). 
\end{proposition}
\begin{proof}
    Let \(\varphi : [c, d] \to [a, b]\) be a diffeomorphism with \(c < d\). Then \textred{Fill out!}
\end{proof}

\begin{definition}[0-forms and the Global Differential]
    A \textbf{0-form} on \(M\) is a smooth function \(f: \mathcal{M}\to \mathbb{R} \). Define the \(\mathbb{R}\)-linear operator \begin{align*}
        d: \left\{ \text{0-forms} \right\} \to \left\{ \text{1-forms} \right\} 
    \end{align*} by it's action on \(v \in T_p M\)  \begin{align*}
        df(p)(v) = vf.
    \end{align*}
    In local coordinates \(x^1, \dots , x^n\) we have \begin{align*}
        df = \frac{\partial f}{\partial x^i} dx^i.
    \end{align*} 
\end{definition}

This is \textbf{exactly} what Lee calls the "global differential", and hence we've already seen this before and its properties. We will later call it the exterior derivative. Note that the global differential satisfies the Leibniz property. \textred{show this!}

\subsubsection{Integration and Exactness}
\begin{theorem}[Fundamental Theorem of Line Integrals]
    If \(f: \mathcal{M}\to \mathbb{R} \) is a smooth map and \(\gamma : [a, b] \to  M\) a smooth curve, then \begin{align*}
        \int _\gamma df = f(\gamma (b)) - f(\gamma (a))
    \end{align*}  
\end{theorem}
\begin{proof}
    \textred{Do it!}
\end{proof}

\begin{definition}[Exact 1-form]
    Let \(\alpha\) be a 1-form on \(M\). We say that \(\alpha\) is \textbf{exact} if \(\alpha = df\) for some function \(f: \mathcal{M}\to \mathbb{R} \).
\end{definition}

\begin{proposition}[Integrating Exact 1-forms]
    Let \(\alpha\) be a 1-form on \(M\). Then \(\alpha\) is exact if and only if \begin{align}\label{prop:integrating_exact_1form}
        \text{for } \gamma : [a, b] \to  M\, \text{, } \int _\gamma \alpha \text{ depends only on } \gamma (a) \text{ and } \gamma (b)
    \end{align}  
\end{proposition}
\begin{proof}
    \textred{Fill out!}
\end{proof}

\begin{proposition}[Exactness in \(\mathbb{R} ^n\)]
    Let \(\alpha = \alpha _i dx^i\) be a 1-form on \(\mathbb{R} ^n\). Then \(\alpha \) is exact if and only if \begin{align*}
        \frac{\partial \alpha _i}{\partial x^j} = \frac{\partial \alpha _j}{\partial x^i}  
    \end{align*}
    for all \(i, j = 1, \dots , n\).   
\end{proposition}

\begin{remark}
    The above result does not generalize to manifolds other than \(\mathbb{R} ^n\)! This will be illustrated by the following example. As we will see later, there is a precise notion of to what extent this condition fails given the manifold we are working on. Measuring this failure will be very important for generalizing integration to manifolds, as far as I know. See notes by Terry Tao.
\end{remark}

\begin{example}
    Consider the 1-form \begin{align*}
        \alpha  = \frac{xdy - ydx}{x^{2} +y^{2} }
    \end{align*}
    on \(\mathbb{R} ^2 \setminus \left\{ 0 \right\} \). It satisfies the hypothesis of the partial derivatives, as can be checked, but \(\alpha \) is still not exact! 
    
    To see why, consider the path \(\gamma : [0, 2 \pi ] \to  \mathbb{R} ^2 \setminus \left\{ 0 \right\} \) given by \(\gamma (t) = (\cos t, \sin t)\). Then \begin{align*}
        \int _\gamma \alpha  &= \int _0 ^2\pi  \left( \frac{xdy - ydx}{x^{2} +y^{2} } \right) \left( -\sin t \frac{\partial}{\partial x} + \cos t \frac{\partial}{\partial y} \right) dt\\
        &= \int _0 ^{2 \pi } \left( \cos (t) dy - \sin (t) dx \right)\left( -\sin t \frac{\partial}{\partial x} + \cos t \frac{\partial}{\partial y} \right) dt \\
        &= \int _0 ^{2 \pi } \left( \cos ^{2} t + \sin ^{2} t \right) dt \\
        &= \int _0 ^{2 \pi } dt \\
        &= 2 \pi 
    \end{align*}
    \textred{second line in above manipulation: is it a vector field, or should there be some points we are evaluating at?}

    But according to the reparameterisation invariance of integrals of 1-forms, we could just as well have chosen a path \(\gamma_1 : [0, 4 \pi ]\) or even the trivial path \(\gamma _0 : [0, 0]\) - they all share the same starting an endpoints (and orientation) \textred{the trivial path is a bit questionable since \(0 < 0\) isn't true...}, but they would produce different answers. Hence \(\alpha\) isn't exact, as the number we get out depends also on the path \(\gamma\), not just \(\gamma (a = 0) = (1, 0)\) and \(\gamma (b = 2 \pi ) = (1, 0)\).

    Switching to polar coordinates, we locally find that \(\alpha  = d \theta \). As we'll see later, we can think of this 1-form as a sort of \(\alpha  = d \theta \) everywhere \textit{locally}, in the sense that we will see that for this \(\alpha\), \begin{align*}
        \int _\gamma \alpha = 2\pi\ \cdot  (\text{winding number of \(\gamma \) around 0})
    \end{align*} 
    where the winding number is always an integer!
\end{example}

As the last example hinted at, the failure to be exact even when the 1-form satisfies the partial derivative criteria is related to the topology of the manifold. Note however that if \(n > 2\), then all 1-forms on \(\mathbb{R} ^n \setminus \left\{ 0 \right\} \) satisfying the partial derivative criterion will also be exact. I assume this has something to do with the fundamental group and being able to pull a loop around the puncture at the origin in all but 2 dimensions (in 1D we cannot have a loop). This we will show by studying de Rham cohomology.

\subsubsection{Introduction to 2-forms}
\begin{definition}[2-form]
    A \textbf{2-form} on \(\mathcal{M} \) is a smooth section \(\beta \) of the vector bundle \((TM \otimes TM)^{\ast} \), which is antisymmetric. That is, for each \(p \in \mathcal{M} \), \(\beta (p): T_{p} \mathcal{M} \times T_p \mathcal{M}  \to \mathbb{R} \) is a function that \begin{enumerate}
        \item is bilinear.
        \item is antisymmetric. 
        \item depends smoothly on \(p\).  
    \end{enumerate}

    The first condition means that it descends to the tensor product \(T_p \mathcal{M}  \otimes T_p \mathcal{M} \) due to the universal property of the tensor product. See last lecture.

    In local coordinates \(x^1, \dots , x^n\), if \(i \neq j\), we define \(dx^i dx^j\) to be the 2-form such that \begin{align*}
        dx^i dx^j \left( \frac{\partial}{\partial x^k}, \frac{\partial}{\partial x^l}\right) = \delta ^i_ k \delta ^j _l
    \end{align*}   
    \textred{Are these supposed to be evaluated at a point? Or are they these type of global tangent vectors that restrict to the basis for each points?}
\end{definition}

\begin{proposition}
    Locally, any 2-form can be written uniquely as \begin{align*}
        \sum_{i < j} \beta _{ij} dx^i dx^j 
    \end{align*}

    We'll prove this later in a more general setting when looking at \(k\)-forms.
\end{proposition}

\begin{selfnote}
    Write out the proofs from this lecture and make sure you understand when there is supposed to be a point attached to the bases vectors for the tangent spaces and when there shouldn't be. Spell out once and for all what we mean when we say "depends smoothly on \(p\)". Write an addendum on the universal property of the tensor product as introduced last time. Central theme: Any bilinear map descends to the tensor space. 
\end{selfnote}

\newpage\lecture{19}{Thu 30 Oct}{2-forms, closed 1-forms and the first de Rham cohomology}

\paragraph{Abstract} The lecture focused on introducing 2-forms and relating them to 1-forms via. the exterior derivative introduced last time. We looked at alternative descriptions of 2-forms (actions at a point vs. actions on vector fields).

We revisited the exterior derivative turning 0-forms into 1-forms and showed how it should act on 1-forms to turn them into 2-forms. We first did the definition of this action in local coordinates. Hence to make sure it was a well-defined concept, we showed that the definition was independent of the chart chosen. Subsequently we introduced the coordinate free definition of the exterior derivatives action on 1-forms and showed that they were the same. This required the characterization of a 2-form as acting on vector-field and being bilinear with respect to function multiplication of vector fields, i.e. \begin{align*}
    \beta (fV, gW) = fg \beta (V, W)
\end{align*}

Introducing the notion of a closed differential, we then saw how \begin{align*}
    d (d \alpha ) = 0 \iff \frac{\partial \alpha _i}{\partial x^j} = \frac{\partial \alpha _j}{\partial x^i}  
\end{align*}
Since by construction, if \(f\) is a 0-form in \(\mathbb{R} ^n\), then \(df = \alpha \) is an exact differential, we immediately have made it clear that in \(\mathbb{R} ^n\), an exact 1-form is closed (by the previous lecture). Defining \begin{align*}
    H^1_{\text{dR}} \left(\mathcal{M} \right) = \frac{\left\{ \text{ closed 1-forms on } \mathcal{M} \ \right\} }{\left\{ \text{ exact 1-forms on } \mathcal{M} \ \right\} }
\end{align*}

In other words, we showed that
\begin{align*}
    H^1_{\text{dR}} \left(\mathbb{R} ^n\right) = \left\{ 0 \right\} 
\end{align*}




\end{document}

