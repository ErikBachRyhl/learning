\documentclass[11pt]{article}
\input{../preamble.tex}   % path is relative to the topic folder

\title{Introduction to Partial Differential Equations}
\author{Erik Bach Ryhl}
\date{\today}

\graphicspath{{./figures}}

\begin{document}
\maketitle
\tableofcontents
\newpage

\section{Borthwick Chapter 7 - Function Spaces Basics}

What does it mean for a sequence of functions \(f_n\) to converge to some function \(f\)? To even answer this question, we of course need to specify some norm within we consider this convergence with respect to. Hence there will always be a norm implied when working with convergence (this is true regardless of us considering functions or regular sequences). 

Each function could for example be a partial sum, so this also covers convergence of series when \(n \to \infty\).

\subsection{Hilbert Spaces and Banach Spaces}
\begin{definition}
    A \textbf{norm} on a vector space \(V\) is a function \(|| \cdot ||: V \to \mathbb{R} ^{\geq 0}\) satisfying \begin{itemize}
        \item \(||x|| = 0 \iff x = 0\)
        \item \(||cx|| = c ||x||\) for any constant \(c\) in the field of \(V\)
        \item \(||x + y|| \leq ||x|| + ||y||\)       
    \end{itemize}
\end{definition}

We can now consider whether we can give the same vector space \(V\) different norms. A common family of norms are the \(p\)-norms: \begin{align*}
    ||x||_p = \left( |x_1|^p + \dots + |x_n| ^p \right)^{1 / p}, \qquad p \geq 1
\end{align*}  
where the condition on \(p\) is necessary for the triangle inequality to not fail (we need our function to be convex, I think is the property). Hence for example \((\mathbb{R} ^n, || \cdot ||_p)\) is a whole family of vector spaces with the same underlying set, but with different notions of norm. 

Any vector space with a norm has a vector space algebra and topology and geometry induced by the norm. \textred{Understand this better!}. We therefore expect that different norms will induce different topologies and geometries. As it turns out, for \textit{finite} dimensional vector spaces, we have the inequality \begin{align*}
    ||x||_p \leq 2 ||x||_2
\end{align*}
which has the consequence that the topologies induced are in fact equivalent. \textred{Get back to showing these things one day!}

But in infinite dimensions, this is \textbf{not} the case.  

\begin{definition}
    A \textbf{Banach space} is a complete, normed vector space, \((V, || \cdot ||)\).  
\end{definition}

\begin{example}
    \(C^0, C^1, \dots , C^k\) are all Banach spaces for finite \(k\). Remember that \(||f||_{C^0} = \operatorname{max} _{x \in \Omega } |f(x)| \), \(||f||_{C^1} = \operatorname{max} _{x \in \Omega } |f(x)| + \operatorname{max} _{x \in \Omega } |\frac{df}{dx}(x)|\) etc.  \textred{fill out these norms!}. 

    But a very frustrating fact is that \(C^\infty\) is \textit{not} a Banach space.  
\end{example}

\begin{definition}
    An \textbf{inner product} is a bilinear function \begin{align*}
        \left\langle \cdot , \cdot \right\rangle : V \times V \to \mathbb{R},
    \end{align*} 
that obeys \begin{enumerate}
    \item \( \left\langle v , v \right\rangle \geq 0\) is a norm (the \textbf{induced norm})
    \item it is bilinear 
\end{enumerate}
If \(V\) is a complex vector space, then the inner products maps into \(\mathbb{C} \) and \(\left\langle  v,\alpha w \right\rangle = \overline{\alpha}  \left\langle v, w \right\rangle \) (yes, the mathematician's convention is opposite the physicists.)
\end{definition}

\begin{lemma}[Cauchy-Schwartz]
    \(\forall v, w \in V\), \begin{align*}
        \left| \left\langle v, w \right\rangle  \right| \leq ||v|| \cdot ||w||.
    \end{align*} 
\end{lemma}
\begin{proof}
    It is an algebraic trick to prove it in the finite dimensional case. But I do not know how the proof goes in the infinite dimensional case. \textred{This would be cool to learn at one point!}
\end{proof}

\newpage\section{Numerical Techniques}
\textbf{Key concepts}
\begin{itemize}
    \item Discretisation map \(\mathcal{D} : \mathbb{R} ^N \to  L^2 (\Omega; \mathbb{R} )\) 
    \item Projection map 
\end{itemize} 

\newpage\section{Integral Solutions, Green's Functions and Fourier Transforms}

\textbf{Abstract:} Where are we going with this? What do we know now? What is the main motivating question for the next section? What are questions we are still totally unable to answer? 

\newpage\lecture{22}{Fri 24 Oct}{Maximum Principles I: Poisson's Formula}
\paragraph{Main Idea} We saw in lecture 9 how to solve (Poisson's equation?) in general on a (circular?) disk in general by doing a Fourier series of our boundary condition function which we could then plug in the coefficients for in the general solution. But this is tedious and takes much work to do every time.

So what if we just keep the function on the general abstract form an work with the Fourier coefficients as abstract entities? Can we rewrite the whole expression in a nice way? The answer is affirmative (under certain conditions like uniform convergence (met due to \(L^2\) arguments I think, check this out)) and on certain domains. 

To do this "trick" we will introduce harmonic functions, harmonic polynomials and see that going to complex variables shows that \(z^n\) generates harmonic polynomials in both real and imaginary parts. These in fact generate each "half" of a binomial expansion in the polynomial \((x + y)^n\), but just with some alternating signs due to \(z^n = (x + iy)^n\). Pretty cool stuff. Now, are these a basis for all harmonic polynomials? It will turn out that the answer is yes I think. Of course we have strong shades of \(z^n\) being a basis for all analytic functions, and each analytic function can be split into harmonic conjugate real and imaginary parts. So I don't think this should be too hard to prove with some methods from complex analysis. Maybe it is lowkey already proven, just not stated in that way. 

Before we prove Poisson, we introduce the idea of integral kernels and dummy variables. With this form, 

Anyway, we prove Poisson's formula as the first example of going directly to an integral solution of a Partial Differential Equaion. 

Testing


\textbf{Key Concepts} 

\newpage\subsection{Example Problems}
\begin{note}
    Solve these problems you missed: 
    
    \textbf{Olver 4.3.25 (d)}: \begin{align*}
        \Delta u = 0,\quad x^{2}+y^{2}<1,\qquad \dfrac{\partial u}{\partial \mathbf n} = x\ \text{on } x^{2}+y^{2}=1.
    \end{align*}

    \textbf{Olver 4.3.45}: Let \(p(x,y)\) be a polynomial (not necessarily harmonic). Suppose \(u(x,y)\) is harmonic and equals \(p(x,y)\) on the unit circle \(x^{2} + y^{2} = 1\). Prove that \(u(x, y)\) is a harmonic polynomial. 
\end{note}

\end{document}




